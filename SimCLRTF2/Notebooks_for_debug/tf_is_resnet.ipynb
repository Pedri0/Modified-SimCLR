{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Contains definitions for the post-activation form of Residual Networks.\n",
    "\n",
    "Residual networks (ResNets) were proposed in:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "\"\"\"\n",
    "import tensorflow.compat.v2 as tf\n",
    "\n",
    "BATCH_NORM_EPSILON = 1e-5\n",
    "\n",
    "\n",
    "class BatchNormRelu(tf.keras.layers.Layer):  # pylint: disable=missing-docstring\n",
    "\n",
    "  def __init__(self,\n",
    "               relu=True,\n",
    "               init_zero=False,\n",
    "               center=True,\n",
    "               scale=True,\n",
    "               data_format='channels_last',\n",
    "               **kwargs):\n",
    "    super(BatchNormRelu, self).__init__(**kwargs)\n",
    "    self.relu = relu\n",
    "    if init_zero:\n",
    "      gamma_initializer = tf.zeros_initializer()\n",
    "    else:\n",
    "      gamma_initializer = tf.ones_initializer()\n",
    "    if data_format == 'channels_first':\n",
    "      axis = 1\n",
    "    else:\n",
    "      axis = -1\n",
    "    if True:\n",
    "      # TODO(srbs): Set fused=True\n",
    "      # Batch normalization layers with fused=True only support 4D input\n",
    "      # tensors.\n",
    "      self.bn = tf.keras.layers.experimental.SyncBatchNormalization(\n",
    "          axis=axis,\n",
    "          momentum=0.9,\n",
    "          epsilon=BATCH_NORM_EPSILON,\n",
    "          center=center,\n",
    "          scale=scale,\n",
    "          gamma_initializer=gamma_initializer)\n",
    "    else:\n",
    "      # TODO(srbs): Set fused=True\n",
    "      # Batch normalization layers with fused=True only support 4D input\n",
    "      # tensors.\n",
    "      self.bn = tf.keras.layers.BatchNormalization(\n",
    "          axis=axis,\n",
    "          momentum=0.9,\n",
    "          epsilon=BATCH_NORM_EPSILON,\n",
    "          center=center,\n",
    "          scale=scale,\n",
    "          fused=False,\n",
    "          gamma_initializer=gamma_initializer)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    inputs = self.bn(inputs, training=training)\n",
    "    if self.relu:\n",
    "      inputs = tf.nn.relu(inputs)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class DropBlock(tf.keras.layers.Layer):  # pylint: disable=missing-docstring\n",
    "\n",
    "  def __init__(self,\n",
    "               keep_prob,\n",
    "               dropblock_size,\n",
    "               data_format='channels_last',\n",
    "               **kwargs):\n",
    "    self.keep_prob = keep_prob\n",
    "    self.dropblock_size = dropblock_size\n",
    "    self.data_format = data_format\n",
    "    super(DropBlock, self).__init__(**kwargs)\n",
    "\n",
    "  def call(self, net, training):\n",
    "    keep_prob = self.keep_prob\n",
    "    dropblock_size = self.dropblock_size\n",
    "    data_format = self.data_format\n",
    "    if not training or keep_prob is None:\n",
    "      return net\n",
    "\n",
    "    tf.logging.info(\n",
    "        'Applying DropBlock: dropblock_size {}, net.shape {}'.format(\n",
    "            dropblock_size, net.shape))\n",
    "\n",
    "    if data_format == 'channels_last':\n",
    "      _, width, height, _ = net.get_shape().as_list()\n",
    "    else:\n",
    "      _, _, width, height = net.get_shape().as_list()\n",
    "    if width != height:\n",
    "      raise ValueError('Input tensor with width!=height is not supported.')\n",
    "\n",
    "    dropblock_size = min(dropblock_size, width)\n",
    "    # seed_drop_rate is the gamma parameter of DropBlcok.\n",
    "    seed_drop_rate = (1.0 - keep_prob) * width**2 / dropblock_size**2 / (\n",
    "        width - dropblock_size + 1)**2\n",
    "\n",
    "    # Forces the block to be inside the feature map.\n",
    "    w_i, h_i = tf.meshgrid(tf.range(width), tf.range(width))\n",
    "    valid_block_center = tf.logical_and(\n",
    "        tf.logical_and(w_i >= int(dropblock_size // 2),\n",
    "                       w_i < width - (dropblock_size - 1) // 2),\n",
    "        tf.logical_and(h_i >= int(dropblock_size // 2),\n",
    "                       h_i < width - (dropblock_size - 1) // 2))\n",
    "\n",
    "    valid_block_center = tf.expand_dims(valid_block_center, 0)\n",
    "    valid_block_center = tf.expand_dims(\n",
    "        valid_block_center, -1 if data_format == 'channels_last' else 0)\n",
    "\n",
    "    randnoise = tf.random_uniform(net.shape, dtype=tf.float32)\n",
    "    block_pattern = (\n",
    "        1 - tf.cast(valid_block_center, dtype=tf.float32) + tf.cast(\n",
    "            (1 - seed_drop_rate), dtype=tf.float32) + randnoise) >= 1\n",
    "    block_pattern = tf.cast(block_pattern, dtype=tf.float32)\n",
    "\n",
    "    if dropblock_size == width:\n",
    "      block_pattern = tf.reduce_min(\n",
    "          block_pattern,\n",
    "          axis=[1, 2] if data_format == 'channels_last' else [2, 3],\n",
    "          keepdims=True)\n",
    "    else:\n",
    "      if data_format == 'channels_last':\n",
    "        ksize = [1, dropblock_size, dropblock_size, 1]\n",
    "      else:\n",
    "        ksize = [1, 1, dropblock_size, dropblock_size]\n",
    "      block_pattern = -tf.nn.max_pool(\n",
    "          -block_pattern,\n",
    "          ksize=ksize,\n",
    "          strides=[1, 1, 1, 1],\n",
    "          padding='SAME',\n",
    "          data_format='NHWC' if data_format == 'channels_last' else 'NCHW')\n",
    "\n",
    "    percent_ones = (\n",
    "        tf.cast(tf.reduce_sum((block_pattern)), tf.float32) /\n",
    "        tf.cast(tf.size(block_pattern), tf.float32))\n",
    "\n",
    "    net = net / tf.cast(percent_ones, net.dtype) * tf.cast(\n",
    "        block_pattern, net.dtype)\n",
    "    return net\n",
    "\n",
    "\n",
    "class FixedPadding(tf.keras.layers.Layer):  # pylint: disable=missing-docstring\n",
    "\n",
    "  def __init__(self, kernel_size, data_format='channels_last', **kwargs):\n",
    "    super(FixedPadding, self).__init__(**kwargs)\n",
    "    self.kernel_size = kernel_size\n",
    "    self.data_format = data_format\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    kernel_size = self.kernel_size\n",
    "    data_format = self.data_format\n",
    "    pad_total = kernel_size - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    if data_format == 'channels_first':\n",
    "      padded_inputs = tf.pad(\n",
    "          inputs, [[0, 0], [0, 0], [pad_beg, pad_end], [pad_beg, pad_end]])\n",
    "    else:\n",
    "      padded_inputs = tf.pad(\n",
    "          inputs, [[0, 0], [pad_beg, pad_end], [pad_beg, pad_end], [0, 0]])\n",
    "\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "class Conv2dFixedPadding(tf.keras.layers.Layer):  # pylint: disable=missing-docstring\n",
    "\n",
    "  def __init__(self,\n",
    "               filters,\n",
    "               kernel_size,\n",
    "               strides,\n",
    "               data_format='channels_last',\n",
    "               **kwargs):\n",
    "    super(Conv2dFixedPadding, self).__init__(**kwargs)\n",
    "    if strides > 1:\n",
    "      self.fixed_padding = FixedPadding(kernel_size, data_format=data_format)\n",
    "    else:\n",
    "      self.fixed_padding = None\n",
    "    self.conv2d = tf.keras.layers.Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        padding=('SAME' if strides == 1 else 'VALID'),\n",
    "        use_bias=False,\n",
    "        kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "        data_format=data_format)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    if self.fixed_padding:\n",
    "      inputs = self.fixed_padding(inputs, training=training)\n",
    "    return self.conv2d(inputs, training=training)\n",
    "\n",
    "\n",
    "class IdentityLayer(tf.keras.layers.Layer):\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    return tf.identity(inputs)\n",
    "\n",
    "\n",
    "class SK_Conv2D(tf.keras.layers.Layer):  # pylint: disable=invalid-name\n",
    "  \"\"\"Selective kernel convolutional layer (https://arxiv.org/abs/1903.06586).\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               filters,\n",
    "               strides,\n",
    "               sk_ratio,\n",
    "               min_dim=32,\n",
    "               data_format='channels_last',\n",
    "               **kwargs):\n",
    "    super(SK_Conv2D, self).__init__(**kwargs)\n",
    "    self.data_format = data_format\n",
    "    self.filters = filters\n",
    "    self.sk_ratio = sk_ratio\n",
    "    self.min_dim = min_dim\n",
    "\n",
    "    # Two stream convs (using split and both are 3x3).\n",
    "    self.conv2d_fixed_padding = Conv2dFixedPadding(\n",
    "        filters=2 * filters,\n",
    "        kernel_size=3,\n",
    "        strides=strides,\n",
    "        data_format=data_format)\n",
    "    self.batch_norm_relu = BatchNormRelu(data_format=data_format)\n",
    "\n",
    "    # Mixing weights for two streams.\n",
    "    mid_dim = max(int(filters * sk_ratio), min_dim)\n",
    "    self.conv2d_0 = tf.keras.layers.Conv2D(\n",
    "        filters=mid_dim,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "        use_bias=False,\n",
    "        data_format=data_format)\n",
    "    self.batch_norm_relu_1 = BatchNormRelu(data_format=data_format)\n",
    "    self.conv2d_1 = tf.keras.layers.Conv2D(\n",
    "        filters=2 * filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "        use_bias=False,\n",
    "        data_format=data_format)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    channel_axis = 1 if self.data_format == 'channels_first' else 3\n",
    "    pooling_axes = [2, 3] if self.data_format == 'channels_first' else [1, 2]\n",
    "\n",
    "    # Two stream convs (using split and both are 3x3).\n",
    "    inputs = self.conv2d_fixed_padding(inputs, training=training)\n",
    "    inputs = self.batch_norm_relu(inputs, training=training)\n",
    "    inputs = tf.stack(tf.split(inputs, num_or_size_splits=2, axis=channel_axis))\n",
    "\n",
    "    # Mixing weights for two streams.\n",
    "    global_features = tf.reduce_mean(\n",
    "        tf.reduce_sum(inputs, axis=0), pooling_axes, keepdims=True)\n",
    "    global_features = self.conv2d_0(global_features, training=training)\n",
    "    global_features = self.batch_norm_relu_1(global_features, training=training)\n",
    "    mixing = self.conv2d_1(global_features, training=training)\n",
    "    mixing = tf.stack(tf.split(mixing, num_or_size_splits=2, axis=channel_axis))\n",
    "    mixing = tf.nn.softmax(mixing, axis=0)\n",
    "\n",
    "    return tf.reduce_sum(inputs * mixing, axis=0)\n",
    "\n",
    "\n",
    "class SE_Layer(tf.keras.layers.Layer):  # pylint: disable=invalid-name\n",
    "  \"\"\"Squeeze and Excitation layer (https://arxiv.org/abs/1709.01507).\"\"\"\n",
    "\n",
    "  def __init__(self, filters, se_ratio, data_format='channels_last', **kwargs):\n",
    "    super(SE_Layer, self).__init__(**kwargs)\n",
    "    self.data_format = data_format\n",
    "    self.se_reduce = tf.keras.layers.Conv2D(\n",
    "        max(1, int(filters * se_ratio)),\n",
    "        kernel_size=[1, 1],\n",
    "        strides=[1, 1],\n",
    "        kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "        padding='same',\n",
    "        data_format=data_format,\n",
    "        use_bias=True)\n",
    "    self.se_expand = tf.keras.layers.Conv2D(\n",
    "        None,  # This is filled later in build().\n",
    "        kernel_size=[1, 1],\n",
    "        strides=[1, 1],\n",
    "        kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "        padding='same',\n",
    "        data_format=data_format,\n",
    "        use_bias=True)\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.se_expand.filters = input_shape[-1]\n",
    "    super(SE_Layer, self).build(input_shape)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    spatial_dims = [2, 3] if self.data_format == 'channels_first' else [1, 2]\n",
    "    se_tensor = tf.reduce_mean(inputs, spatial_dims, keepdims=True)\n",
    "    se_tensor = self.se_expand(tf.nn.relu(self.se_reduce(se_tensor)))\n",
    "    return tf.sigmoid(se_tensor) * inputs\n",
    "\n",
    "\n",
    "class ResidualBlock(tf.keras.layers.Layer):  # pylint: disable=missing-docstring\n",
    "\n",
    "  def __init__(self,\n",
    "               filters,\n",
    "               strides,\n",
    "               use_projection=False,\n",
    "               data_format='channels_last',\n",
    "               dropblock_keep_prob=None,\n",
    "               dropblock_size=None,\n",
    "               **kwargs):\n",
    "    super(ResidualBlock, self).__init__(**kwargs)\n",
    "    del dropblock_keep_prob\n",
    "    del dropblock_size\n",
    "    self.conv2d_bn_layers = []\n",
    "    self.shortcut_layers = []\n",
    "    if use_projection:\n",
    "      if False:  # Use ResNet-D (https://arxiv.org/abs/1812.01187)\n",
    "        if strides > 1:\n",
    "          self.shortcut_layers.append(FixedPadding(2, data_format))\n",
    "        self.shortcut_layers.append(\n",
    "            tf.keras.layers.AveragePooling2D(\n",
    "                pool_size=2,\n",
    "                strides=strides,\n",
    "                padding='SAME' if strides == 1 else 'VALID',\n",
    "                data_format=data_format))\n",
    "        self.shortcut_layers.append(\n",
    "            Conv2dFixedPadding(\n",
    "                filters=filters,\n",
    "                kernel_size=1,\n",
    "                strides=1,\n",
    "                data_format=data_format))\n",
    "      else:\n",
    "        self.shortcut_layers.append(\n",
    "            Conv2dFixedPadding(\n",
    "                filters=filters,\n",
    "                kernel_size=1,\n",
    "                strides=strides,\n",
    "                data_format=data_format))\n",
    "      self.shortcut_layers.append(\n",
    "          BatchNormRelu(relu=False, data_format=data_format))\n",
    "\n",
    "    self.conv2d_bn_layers.append(\n",
    "        Conv2dFixedPadding(\n",
    "            filters=filters,\n",
    "            kernel_size=3,\n",
    "            strides=strides,\n",
    "            data_format=data_format))\n",
    "    self.conv2d_bn_layers.append(BatchNormRelu(data_format=data_format))\n",
    "    self.conv2d_bn_layers.append(\n",
    "        Conv2dFixedPadding(\n",
    "            filters=filters, kernel_size=3, strides=1, data_format=data_format))\n",
    "    self.conv2d_bn_layers.append(\n",
    "        BatchNormRelu(relu=False, init_zero=True, data_format=data_format))\n",
    "    if False:\n",
    "      self.se_layer = SE_Layer(filters, 0.1, data_format=data_format)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    shortcut = inputs\n",
    "    for layer in self.shortcut_layers:\n",
    "      # Projection shortcut in first layer to match filters and strides\n",
    "      shortcut = layer(shortcut, training=training)\n",
    "\n",
    "    for layer in self.conv2d_bn_layers:\n",
    "      inputs = layer(inputs, training=training)\n",
    "\n",
    "    if False:\n",
    "      inputs = self.se_layer(inputs, training=training)\n",
    "\n",
    "    return tf.nn.relu(inputs + shortcut)\n",
    "\n",
    "\n",
    "class BottleneckBlock(tf.keras.layers.Layer):\n",
    "  \"\"\"BottleneckBlock.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               filters,\n",
    "               strides,\n",
    "               use_projection=False,\n",
    "               data_format='channels_last',\n",
    "               dropblock_keep_prob=None,\n",
    "               dropblock_size=None,\n",
    "               **kwargs):\n",
    "    super(BottleneckBlock, self).__init__(**kwargs)\n",
    "    self.projection_layers = []\n",
    "    if use_projection:\n",
    "      filters_out = 4 * filters\n",
    "      if False:  # Use ResNet-D (https://arxiv.org/abs/1812.01187)\n",
    "        if strides > 1:\n",
    "          self.projection_layers.append(FixedPadding(2, data_format))\n",
    "        self.projection_layers.append(\n",
    "            tf.keras.layers.AveragePooling2D(\n",
    "                pool_size=2,\n",
    "                strides=strides,\n",
    "                padding='SAME' if strides == 1 else 'VALID',\n",
    "                data_format=data_format))\n",
    "        self.projection_layers.append(\n",
    "            Conv2dFixedPadding(\n",
    "                filters=filters_out,\n",
    "                kernel_size=1,\n",
    "                strides=1,\n",
    "                data_format=data_format))\n",
    "      else:\n",
    "        self.projection_layers.append(\n",
    "            Conv2dFixedPadding(\n",
    "                filters=filters_out,\n",
    "                kernel_size=1,\n",
    "                strides=strides,\n",
    "                data_format=data_format))\n",
    "      self.projection_layers.append(\n",
    "          BatchNormRelu(relu=False, data_format=data_format))\n",
    "    self.shortcut_dropblock = DropBlock(\n",
    "        data_format=data_format,\n",
    "        keep_prob=dropblock_keep_prob,\n",
    "        dropblock_size=dropblock_size)\n",
    "\n",
    "    self.conv_relu_dropblock_layers = []\n",
    "\n",
    "    self.conv_relu_dropblock_layers.append(\n",
    "        Conv2dFixedPadding(\n",
    "            filters=filters, kernel_size=1, strides=1, data_format=data_format))\n",
    "    self.conv_relu_dropblock_layers.append(\n",
    "        BatchNormRelu(data_format=data_format))\n",
    "    self.conv_relu_dropblock_layers.append(\n",
    "        DropBlock(\n",
    "            data_format=data_format,\n",
    "            keep_prob=dropblock_keep_prob,\n",
    "            dropblock_size=dropblock_size))\n",
    "\n",
    "    if False:\n",
    "      self.conv_relu_dropblock_layers.append(\n",
    "          SK_Conv2D(filters, strides, 0.01, data_format=data_format))\n",
    "    else:\n",
    "      self.conv_relu_dropblock_layers.append(\n",
    "          Conv2dFixedPadding(\n",
    "              filters=filters,\n",
    "              kernel_size=3,\n",
    "              strides=strides,\n",
    "              data_format=data_format))\n",
    "      self.conv_relu_dropblock_layers.append(\n",
    "          BatchNormRelu(data_format=data_format))\n",
    "    self.conv_relu_dropblock_layers.append(\n",
    "        DropBlock(\n",
    "            data_format=data_format,\n",
    "            keep_prob=dropblock_keep_prob,\n",
    "            dropblock_size=dropblock_size))\n",
    "\n",
    "    self.conv_relu_dropblock_layers.append(\n",
    "        Conv2dFixedPadding(\n",
    "            filters=4 * filters,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            data_format=data_format))\n",
    "    self.conv_relu_dropblock_layers.append(\n",
    "        BatchNormRelu(relu=False, init_zero=True, data_format=data_format))\n",
    "    self.conv_relu_dropblock_layers.append(\n",
    "        DropBlock(\n",
    "            data_format=data_format,\n",
    "            keep_prob=dropblock_keep_prob,\n",
    "            dropblock_size=dropblock_size))\n",
    "\n",
    "    if False:\n",
    "      self.conv_relu_dropblock_layers.append(\n",
    "          SE_Layer(filters, 0.1, data_format=data_format))\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    shortcut = inputs\n",
    "    for layer in self.projection_layers:\n",
    "      shortcut = layer(shortcut, training=training)\n",
    "    shortcut = self.shortcut_dropblock(shortcut, training=training)\n",
    "\n",
    "    for layer in self.conv_relu_dropblock_layers:\n",
    "      inputs = layer(inputs, training=training)\n",
    "\n",
    "    return tf.nn.relu(inputs + shortcut)\n",
    "\n",
    "\n",
    "class BlockGroup(tf.keras.layers.Layer):  # pylint: disable=missing-docstring\n",
    "\n",
    "  def __init__(self,\n",
    "               filters,\n",
    "               block_fn,\n",
    "               blocks,\n",
    "               strides,\n",
    "               data_format='channels_last',\n",
    "               dropblock_keep_prob=None,\n",
    "               dropblock_size=None,\n",
    "               **kwargs):\n",
    "    self._name = kwargs.get('name')\n",
    "    super(BlockGroup, self).__init__(**kwargs)\n",
    "\n",
    "    self.layers = []\n",
    "    self.layers.append(\n",
    "        block_fn(\n",
    "            filters,\n",
    "            strides,\n",
    "            use_projection=True,\n",
    "            data_format=data_format,\n",
    "            dropblock_keep_prob=dropblock_keep_prob,\n",
    "            dropblock_size=dropblock_size))\n",
    "\n",
    "    for _ in range(1, blocks):\n",
    "      self.layers.append(\n",
    "          block_fn(\n",
    "              filters,\n",
    "              1,\n",
    "              data_format=data_format,\n",
    "              dropblock_keep_prob=dropblock_keep_prob,\n",
    "              dropblock_size=dropblock_size))\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    for layer in self.layers:\n",
    "      inputs = layer(inputs, training=training)\n",
    "    return tf.identity(inputs, self._name)\n",
    "\n",
    "\n",
    "class Resnet(tf.keras.layers.Layer):  # pylint: disable=missing-docstring\n",
    "\n",
    "  def __init__(self,\n",
    "               block_fn,\n",
    "               layers,\n",
    "               width_multiplier,\n",
    "               cifar_stem=False,\n",
    "               data_format='channels_last',\n",
    "               dropblock_keep_probs=None,\n",
    "               dropblock_size=None,\n",
    "               **kwargs):\n",
    "    super(Resnet, self).__init__(**kwargs)\n",
    "    self.data_format = data_format\n",
    "    if dropblock_keep_probs is None:\n",
    "      dropblock_keep_probs = [None] * 4\n",
    "    if not isinstance(dropblock_keep_probs,\n",
    "                      list) or len(dropblock_keep_probs) != 4:\n",
    "      raise ValueError('dropblock_keep_probs is not valid:',\n",
    "                       dropblock_keep_probs)\n",
    "    trainable = True\n",
    "    self.initial_conv_relu_max_pool = []\n",
    "    if cifar_stem:\n",
    "      self.initial_conv_relu_max_pool.append(\n",
    "          Conv2dFixedPadding(\n",
    "              filters=64 * width_multiplier,\n",
    "              kernel_size=3,\n",
    "              strides=1,\n",
    "              data_format=data_format,\n",
    "              trainable=trainable))\n",
    "      self.initial_conv_relu_max_pool.append(\n",
    "          IdentityLayer(name='initial_conv', trainable=trainable))\n",
    "      self.initial_conv_relu_max_pool.append(\n",
    "          BatchNormRelu(data_format=data_format, trainable=trainable))\n",
    "      self.initial_conv_relu_max_pool.append(\n",
    "          IdentityLayer(name='initial_max_pool', trainable=trainable))\n",
    "    else:\n",
    "      if False:  # Use ResNet-D (https://arxiv.org/abs/1812.01187)\n",
    "        self.initial_conv_relu_max_pool.append(\n",
    "            Conv2dFixedPadding(\n",
    "                filters=64 * width_multiplier // 2,\n",
    "                kernel_size=3,\n",
    "                strides=2,\n",
    "                data_format=data_format,\n",
    "                trainable=trainable))\n",
    "        self.initial_conv_relu_max_pool.append(\n",
    "            BatchNormRelu(data_format=data_format, trainable=trainable))\n",
    "        self.initial_conv_relu_max_pool.append(\n",
    "            Conv2dFixedPadding(\n",
    "                filters=64 * width_multiplier // 2,\n",
    "                kernel_size=3,\n",
    "                strides=1,\n",
    "                data_format=data_format,\n",
    "                trainable=trainable))\n",
    "        self.initial_conv_relu_max_pool.append(\n",
    "            BatchNormRelu(data_format=data_format, trainable=trainable))\n",
    "        self.initial_conv_relu_max_pool.append(\n",
    "            Conv2dFixedPadding(\n",
    "                filters=64 * width_multiplier,\n",
    "                kernel_size=3,\n",
    "                strides=1,\n",
    "                data_format=data_format,\n",
    "                trainable=trainable))\n",
    "      else:\n",
    "        self.initial_conv_relu_max_pool.append(\n",
    "            Conv2dFixedPadding(\n",
    "                filters=64 * width_multiplier,\n",
    "                kernel_size=7,\n",
    "                strides=2,\n",
    "                data_format=data_format,\n",
    "                trainable=trainable))\n",
    "      self.initial_conv_relu_max_pool.append(\n",
    "          IdentityLayer(name='initial_conv', trainable=trainable))\n",
    "      self.initial_conv_relu_max_pool.append(\n",
    "          BatchNormRelu(data_format=data_format, trainable=trainable))\n",
    "\n",
    "      self.initial_conv_relu_max_pool.append(\n",
    "          tf.keras.layers.MaxPooling2D(\n",
    "              pool_size=3,\n",
    "              strides=2,\n",
    "              padding='SAME',\n",
    "              data_format=data_format,\n",
    "              trainable=trainable))\n",
    "      self.initial_conv_relu_max_pool.append(\n",
    "          IdentityLayer(name='initial_max_pool', trainable=trainable))\n",
    "\n",
    "    self.block_groups = []\n",
    "    # TODO(srbs): This impl is different from the original one in the case where\n",
    "    # fine_tune_after_block != 4. In that case earlier BN stats were getting\n",
    "    # updated. Now they will not be. Check with Ting to make sure this is ok.\n",
    "    if False:\n",
    "      trainable = True\n",
    "\n",
    "    self.block_groups.append(\n",
    "        BlockGroup(\n",
    "            filters=64 * width_multiplier,\n",
    "            block_fn=block_fn,\n",
    "            blocks=layers[0],\n",
    "            strides=1,\n",
    "            name='block_group1',\n",
    "            data_format=data_format,\n",
    "            dropblock_keep_prob=dropblock_keep_probs[0],\n",
    "            dropblock_size=dropblock_size,\n",
    "            trainable=trainable))\n",
    "\n",
    "    if False:\n",
    "      trainable = True\n",
    "\n",
    "    self.block_groups.append(\n",
    "        BlockGroup(\n",
    "            filters=128 * width_multiplier,\n",
    "            block_fn=block_fn,\n",
    "            blocks=layers[1],\n",
    "            strides=2,\n",
    "            name='block_group2',\n",
    "            data_format=data_format,\n",
    "            dropblock_keep_prob=dropblock_keep_probs[1],\n",
    "            dropblock_size=dropblock_size,\n",
    "            trainable=trainable))\n",
    "\n",
    "    if False:\n",
    "      trainable = True\n",
    "\n",
    "    self.block_groups.append(\n",
    "        BlockGroup(\n",
    "            filters=256 * width_multiplier,\n",
    "            block_fn=block_fn,\n",
    "            blocks=layers[2],\n",
    "            strides=2,\n",
    "            name='block_group3',\n",
    "            data_format=data_format,\n",
    "            dropblock_keep_prob=dropblock_keep_probs[2],\n",
    "            dropblock_size=dropblock_size,\n",
    "            trainable=trainable))\n",
    "\n",
    "    if False:\n",
    "      trainable = True\n",
    "\n",
    "    self.block_groups.append(\n",
    "        BlockGroup(\n",
    "            filters=512 * width_multiplier,\n",
    "            block_fn=block_fn,\n",
    "            blocks=layers[3],\n",
    "            strides=2,\n",
    "            name='block_group4',\n",
    "            data_format=data_format,\n",
    "            dropblock_keep_prob=dropblock_keep_probs[3],\n",
    "            dropblock_size=dropblock_size,\n",
    "            trainable=trainable))\n",
    "\n",
    "    if False:\n",
    "      # This case doesn't really matter.\n",
    "      trainable = True\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    for layer in self.initial_conv_relu_max_pool:\n",
    "      inputs = layer(inputs, training=training)\n",
    "\n",
    "    for i, layer in enumerate(self.block_groups):\n",
    "      if False:\n",
    "        inputs = tf.stop_gradient(inputs)\n",
    "      inputs = layer(inputs, training=training)\n",
    "    if False:\n",
    "      inputs = tf.stop_gradient(inputs)\n",
    "    if self.data_format == 'channels_last':\n",
    "      inputs = tf.reduce_mean(inputs, [1, 2])\n",
    "    else:\n",
    "      inputs = tf.reduce_mean(inputs, [2, 3])\n",
    "\n",
    "    inputs = tf.identity(inputs, 'final_avg_pool')\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def resnet(resnet_depth,\n",
    "           width_multiplier,\n",
    "           cifar_stem=False,\n",
    "           data_format='channels_last',\n",
    "           dropblock_keep_probs=None,\n",
    "           dropblock_size=None):\n",
    "  \"\"\"Returns the ResNet model for a given size and number of output classes.\"\"\"\n",
    "  model_params = {\n",
    "      18: {\n",
    "          'block': ResidualBlock,\n",
    "          'layers': [2, 2, 2, 2]\n",
    "      },\n",
    "      34: {\n",
    "          'block': ResidualBlock,\n",
    "          'layers': [3, 4, 6, 3]\n",
    "      },\n",
    "      50: {\n",
    "          'block': BottleneckBlock,\n",
    "          'layers': [3, 4, 6, 3]\n",
    "      },\n",
    "      101: {\n",
    "          'block': BottleneckBlock,\n",
    "          'layers': [3, 4, 23, 3]\n",
    "      },\n",
    "      152: {\n",
    "          'block': BottleneckBlock,\n",
    "          'layers': [3, 8, 36, 3]\n",
    "      },\n",
    "      200: {\n",
    "          'block': BottleneckBlock,\n",
    "          'layers': [3, 24, 36, 3]\n",
    "      }\n",
    "  }\n",
    "\n",
    "  if resnet_depth not in model_params:\n",
    "    raise ValueError('Not a valid resnet_depth:', resnet_depth)\n",
    "\n",
    "  params = model_params[resnet_depth]\n",
    "  return Resnet(\n",
    "      params['block'],\n",
    "      params['layers'],\n",
    "      width_multiplier,\n",
    "      cifar_stem=cifar_stem,\n",
    "      dropblock_keep_probs=dropblock_keep_probs,\n",
    "      dropblock_size=dropblock_size,\n",
    "      data_format=data_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable = (a == 'finetune' and f_a == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'pretrain'\n",
    "f_a = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = resnet(\n",
    "        resnet_depth=18,\n",
    "        width_multiplier=1,\n",
    "        cifar_stem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Resnet at 0x7fe3e86fb490>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oscurisimo el metodo :c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_blur(image, height, width, p=1.0):\n",
    "  \"\"\"Randomly blur an image.\n",
    "\n",
    "  Args:\n",
    "    image: `Tensor` representing an image of arbitrary size.\n",
    "    height: Height of output image.\n",
    "    width: Width of output image.\n",
    "    p: probability of applying this transformation.\n",
    "\n",
    "  Returns:\n",
    "    A preprocessed image `Tensor`.\n",
    "  \"\"\"\n",
    "  del width\n",
    "  def _transform(image):\n",
    "    sigma = tf.random.uniform([], 0.1, 2.0, dtype=tf.float32)\n",
    "    return gaussian_blur(\n",
    "        image, kernel_size=height//10, sigma=sigma, padding='SAME')\n",
    "  return random_apply(_transform, p=p, x=image)\n",
    "\n",
    "\n",
    "def batch_random_blur(images_list, height, width, blur_probability=0.5):\n",
    "  \"\"\"Apply efficient batch data transformations.\n",
    "\n",
    "  Args:\n",
    "    images_list: a list of image tensors.\n",
    "    height: the height of image.\n",
    "    width: the width of image.\n",
    "    blur_probability: the probaility to apply the blur operator.\n",
    "\n",
    "  Returns:\n",
    "    Preprocessed feature list.\n",
    "  \"\"\"\n",
    "  def generate_selector(p, bsz):\n",
    "    shape = [bsz, 1, 1, 1]\n",
    "    selector = tf.cast(\n",
    "        tf.less(tf.random.uniform(shape, 0, 1, dtype=tf.float32), p),\n",
    "        tf.float32)\n",
    "    return selector\n",
    "\n",
    "  new_images_list = []\n",
    "  for images in images_list:\n",
    "    images_new = random_blur(images, height, width, p=1.)\n",
    "    selector = generate_selector(blur_probability, tf.shape(images)[0])\n",
    "    images = images_new * selector + images * (1 - selector)\n",
    "    images = tf.clip_by_value(images, 0., 1.)\n",
    "    new_images_list.append(images)\n",
    "\n",
    "  return new_images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow.compat.v2 as tf\n",
    "\n",
    "\n",
    "def build_optimizer(learning_rate):\n",
    "  \"\"\"Returns the optimizer.\"\"\"\n",
    "  if False:\n",
    "    return tf.keras.optimizers.SGD(learning_rate, FLAGS.momentum, nesterov=True)\n",
    "  elif True:\n",
    "    return tf.keras.optimizers.Adam(learning_rate)\n",
    "  elif False:\n",
    "    return None\n",
    "\n",
    "\n",
    "def add_weight_decay(model, adjust_per_optimizer=True):\n",
    "  \"\"\"Compute weight decay from flags.\"\"\"\n",
    "  if False:\n",
    "    # Weight decay are taking care of by optimizer for these cases.\n",
    "    # Except for supervised head, which will be added here.\n",
    "    l2_losses = [\n",
    "        tf.nn.l2_loss(v)\n",
    "        for v in model.trainable_variables\n",
    "        if 'head_supervised' in v.name and 'bias' not in v.name\n",
    "    ]\n",
    "    if l2_losses:\n",
    "      return 1e-6 * tf.add_n(l2_losses)\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "  # TODO(srbs): Think of a way to avoid name-based filtering here.\n",
    "  l2_losses = [\n",
    "      tf.nn.l2_loss(v)\n",
    "      for v in model.trainable_weights\n",
    "      if 'batch_normalization' not in v.name\n",
    "  ]\n",
    "  loss = FLAGS.weight_decay * tf.add_n(l2_losses)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def get_train_steps(num_examples):\n",
    "  \"\"\"Determine the number of training steps.\"\"\"\n",
    "  return 2370\n",
    "\n",
    "\n",
    "class WarmUpAndCosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  \"\"\"Applies a warmup schedule on a given learning rate decay schedule.\"\"\"\n",
    "\n",
    "  def __init__(self, base_learning_rate, num_examples, name=None):\n",
    "    super(WarmUpAndCosineDecay, self).__init__()\n",
    "    self.base_learning_rate = base_learning_rate\n",
    "    self.num_examples = num_examples\n",
    "    self._name = name\n",
    "\n",
    "  def __call__(self, step):\n",
    "    with tf.name_scope(self._name or 'WarmUpAndCosineDecay'):\n",
    "      warmup_steps = int(\n",
    "          round(10 * self.num_examples //\n",
    "                512))\n",
    "      if False:\n",
    "        scaled_lr = self.base_learning_rate * 512 / 256.\n",
    "      elif True:\n",
    "        scaled_lr = self.base_learning_rate * math.sqrt(512)\n",
    "\n",
    "      learning_rate = (\n",
    "          step / float(warmup_steps) * scaled_lr if warmup_steps else scaled_lr)\n",
    "\n",
    "      # Cosine decay learning rate schedule\n",
    "      total_steps = get_train_steps(self.num_examples)\n",
    "      # TODO(srbs): Cache this object.\n",
    "      cosine_decay = tf.keras.experimental.CosineDecay(\n",
    "          scaled_lr, total_steps - warmup_steps)\n",
    "      learning_rate = tf.where(step < warmup_steps, learning_rate,\n",
    "                               cosine_decay(step - warmup_steps))\n",
    "\n",
    "      return learning_rate\n",
    "\n",
    "  def get_config(self):\n",
    "    return {\n",
    "        'base_learning_rate': self.base_learning_rate,\n",
    "        'num_examples': self.num_examples,\n",
    "    }\n",
    "\n",
    "\n",
    "class LinearLayer(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self,\n",
    "               num_classes,\n",
    "               use_bias=True,\n",
    "               use_bn=False,\n",
    "               name='linear_layer',\n",
    "               **kwargs):\n",
    "    # Note: use_bias is ignored for the dense layer when use_bn=True.\n",
    "    # However, it is still used for batch norm.\n",
    "    super(LinearLayer, self).__init__(**kwargs)\n",
    "    self.num_classes = num_classes\n",
    "    self.use_bn = use_bn\n",
    "    self._name = name\n",
    "    if callable(self.num_classes):\n",
    "      num_classes = -1\n",
    "    else:\n",
    "      num_classes = self.num_classes\n",
    "    self.dense = tf.keras.layers.Dense(\n",
    "        num_classes,\n",
    "        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "        use_bias=use_bias and not self.use_bn)\n",
    "    if self.use_bn:\n",
    "      self.bn_relu = BatchNormRelu(relu=False, center=use_bias)\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    # TODO(srbs): Add a new SquareDense layer.\n",
    "    if callable(self.num_classes):\n",
    "      self.dense.units = self.num_classes(input_shape)\n",
    "    super(LinearLayer, self).build(input_shape)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    assert inputs.shape.ndims == 2, inputs.shape\n",
    "    inputs = self.dense(inputs)\n",
    "    if self.use_bn:\n",
    "      inputs = self.bn_relu(inputs, training=training)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class ProjectionHead(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, **kwargs):\n",
    "    out_dim = 128\n",
    "    self.linear_layers = []\n",
    "    if False:\n",
    "      pass  # directly use the output hiddens as hiddens\n",
    "    elif False:\n",
    "      self.linear_layers = [\n",
    "          LinearLayer(\n",
    "              num_classes=out_dim, use_bias=False, use_bn=True, name='l_0')\n",
    "      ]\n",
    "    elif True:\n",
    "      for j in range(3):\n",
    "        if j != 3 - 1:\n",
    "          # for the middle layers, use bias and relu for the output.\n",
    "          self.linear_layers.append(\n",
    "              LinearLayer(\n",
    "                  num_classes=lambda input_shape: int(input_shape[-1]),\n",
    "                  use_bias=True,\n",
    "                  use_bn=True,\n",
    "                  name='nl_%d' % j))\n",
    "        else:\n",
    "          # for the final layer, neither bias nor relu is used.\n",
    "          self.linear_layers.append(\n",
    "              LinearLayer(\n",
    "                  num_classes=128,\n",
    "                  use_bias=False,\n",
    "                  use_bn=True,\n",
    "                  name='nl_%d' % j))\n",
    "\n",
    "    super(ProjectionHead, self).__init__(**kwargs)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    if False:\n",
    "      return inputs  # directly use the output hiddens as hiddens\n",
    "    hiddens_list = [tf.identity(inputs, 'proj_head_input')]\n",
    "    if False:\n",
    "      assert len(self.linear_layers) == 1, len(self.linear_layers)\n",
    "      return hiddens_list.append(self.linear_layers[0](hiddens_list[-1],\n",
    "                                                       training))\n",
    "    elif True:\n",
    "      for j in range(3):\n",
    "        hiddens = self.linear_layers[j](hiddens_list[-1], training)\n",
    "        if j != 3 - 1:\n",
    "          # for the middle layers, use bias and relu for the output.\n",
    "          hiddens = tf.nn.relu(hiddens)\n",
    "        hiddens_list.append(hiddens)\n",
    "\n",
    "    # The first element is the output of the projection head.\n",
    "    # The second element is the input of the finetune head.\n",
    "    proj_head_output = tf.identity(hiddens_list[-1], 'proj_head_output')\n",
    "    return proj_head_output, hiddens_list[0]\n",
    "\n",
    "\n",
    "class SupervisedHead(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, num_classes, name='head_supervised', **kwargs):\n",
    "    super(SupervisedHead, self).__init__(name=name, **kwargs)\n",
    "    self.linear_layer = LinearLayer(num_classes)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    inputs = self.linear_layer(inputs, training)\n",
    "    inputs = tf.identity(inputs, name='logits_sup')\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class Model(tf.keras.models.Model):\n",
    "  \"\"\"Resnet model with projection or supervised layer.\"\"\"\n",
    "\n",
    "  def __init__(self, num_classes, **kwargs):\n",
    "    super(Model, self).__init__(**kwargs)\n",
    "    self.resnet_model = resnet(\n",
    "        resnet_depth=50,\n",
    "        width_multiplier=1,\n",
    "        cifar_stem=False)\n",
    "    self._projection_head = ProjectionHead()\n",
    "    if False:\n",
    "      self.supervised_head = SupervisedHead(num_classes)\n",
    "\n",
    "  def __call__(self, inputs, training):\n",
    "    features = inputs\n",
    "    # Split channels, and optionally apply extra batched augmentation.\n",
    "    features_list = tf.split(\n",
    "        features, num_or_size_splits=1, axis=-1)\n",
    "    if True and training and True:\n",
    "      features_list = batch_random_blur(features_list,\n",
    "                                                  330,\n",
    "                                                  330)\n",
    "    features = tf.concat(features_list, 0)  # (num_transforms * bsz, h, w, c)\n",
    "\n",
    "    # Base network forward pass.\n",
    "    hiddens = self.resnet_model(features, training=training)\n",
    "\n",
    "    # Add heads.\n",
    "    projection_head_outputs, supervised_head_inputs = self._projection_head(\n",
    "        hiddens, training)\n",
    "\n",
    "    if False:\n",
    "      supervised_head_outputs = self.supervised_head(supervised_head_inputs,\n",
    "                                                     training)\n",
    "      return None, supervised_head_outputs\n",
    "    elif False:\n",
    "      # When performing pretraining and linear evaluation together we do not\n",
    "      # want information from linear eval flowing back into pretraining network\n",
    "      # so we put a stop_gradient.\n",
    "      supervised_head_outputs = self.supervised_head(\n",
    "          tf.stop_gradient(supervised_head_inputs), training)\n",
    "      return projection_head_outputs, supervised_head_outputs\n",
    "    else:\n",
    "      return projection_head_outputs, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-4e566fa99347>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMirroredStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodelss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'num_classes'"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    modelss = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Resnet at 0x7fe36022d350>,\n",
       " <__main__.ProjectionHead at 0x7fe3600acf90>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelss.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelss.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    modelss.compile(loss=tf.losses.MeanSquaredError(),metrics=[tf.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (None, 330, 330, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "When subclassing the `Model` class, you should implement a `call` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-0622ee2fa15b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodelss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/SIM/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    443\u001b[0m                            'method accepts an `inputs` argument.')\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m           raise ValueError('You cannot build your model by calling `build` '\n",
      "\u001b[0;32m~/anaconda3/envs/SIM/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \"\"\"\n\u001b[0;32m--> 478\u001b[0;31m     raise NotImplementedError('When subclassing the `Model` class, you should '\n\u001b[0m\u001b[1;32m    479\u001b[0m                               'implement a `call` method.')\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: When subclassing the `Model` class, you should implement a `call` method."
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    modelss.build(input_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SIM",
   "language": "python",
   "name": "sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
